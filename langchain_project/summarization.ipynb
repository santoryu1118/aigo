{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "print(f\"{OPENAI_API_KEY = }\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90686ff93fdc4248"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/modules/model_io/models/chat/\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "\n",
    "text= \"\"\"\n",
    "Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability \\\n",
    "of AI hardware and extensibility of AI models.\n",
    "Mojo is a new programming language that bridges the gap between research and production \\ \n",
    "by combining the best of Python syntax with systems programming and metaprogramming.\n",
    "With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem.\n",
    "When we started Modular, we had no intention of building a new programming language. \\\n",
    "But as we were building our platform with the intent to unify the world’s ML/AI infrastructure, \\\n",
    "we realized that programming across the entire stack was too complicated. Plus, we were writing a \\\n",
    "lot of MLIR by hand and not having a good time.\n",
    "And although accelerators are important, one of the most prevalent and sometimes overlooked \"accelerators\" \\\n",
    "is the host CPU. Nowadays, CPUs have lots of tensor-core-like accelerator blocks and other AI acceleration \\\n",
    "units, but they also serve as the “fallback” for operations that specialized accelerators don’t handle, \\\n",
    "such as data loading, pre- and post-processing, and integrations with foreign systems. \\\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='You are an expert copywriter with expertize in summarizing documents'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the following text:\\n TEXT: {text}')\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(temperature=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f1df84a2cc64a7e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm.get_num_tokens(text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "261d31091af47088"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary_output = llm(messages)\n",
    "print(summary_output)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "249504153b3365b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summarizing Using Prompt Templates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa9f65fc9a5669b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text\", \"language\"],\n",
    "    template= 'Please provide a short and concise summary of the following text:\\n TEXT: {text}. Translate the summary in {language} language.' \n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22087bd37e668177"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "chain.run({'text': text, 'language': 'Korean'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208aa12b09d95879"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Summarizing Using StuffDocumentChain"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34655d5106e8f865"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7ceaaafc09177af6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "with open('files/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# text\n",
    "\n",
    "docs = [Document(page_content=text)]\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "\n",
    "template = '''Write a concise and short summary of the following text.\n",
    "TEXT: `{text}`\n",
    "'''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "output_summary = chain.run(docs)\n",
    "print(output_summary)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165b952cdddbdd69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24669d5d2273921e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('files/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([text])\n",
    "\n",
    "map_prompt = '''\n",
    "Write a short and concise summary of the following:\n",
    "Text: `{text}`\n",
    "CONCISE SUMMARY:\n",
    "'''\n",
    "map_prompt_template = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=map_prompt\n",
    ")\n",
    "\n",
    "combine_prompt = '''\n",
    "Write a concise summary of the following text that covers the key points.\n",
    "Add a title to the summary.\n",
    "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED\n",
    "by BULLET POINTS if possible AND end the summary with a CONCLUSION PHRASE.\n",
    "Text: `{text}`\n",
    "'''\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=['text'])\n",
    "\n",
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=combine_prompt_template,\n",
    "    verbose=False\n",
    ")\n",
    "# output = summary_chain.run(chunks)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8fa9be6d4c931de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e791ed9d03a2f0f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-18T01:47:07.919420Z"
    }
   },
   "id": "51db7d5d0fce69a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "240a437f62c515c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
